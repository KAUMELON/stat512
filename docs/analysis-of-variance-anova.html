<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture: 3 Analysis of Variance (ANOVA) | LECTURE NOTES OF STAT 512</title>
  <meta name="description" content="A BOOK FOR POST GRADUATE PROGRAMME IN AGRICULTURE" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture: 3 Analysis of Variance (ANOVA) | LECTURE NOTES OF STAT 512" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.PNG" />
  <meta property="og:description" content="A BOOK FOR POST GRADUATE PROGRAMME IN AGRICULTURE" />
  <meta name="github-repo" content="https://github.com/KAUMELON/stat512" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture: 3 Analysis of Variance (ANOVA) | LECTURE NOTES OF STAT 512" />
  
  <meta name="twitter:description" content="A BOOK FOR POST GRADUATE PROGRAMME IN AGRICULTURE" />
  <meta name="twitter:image" content="/images/cover.PNG" />

<meta name="author" content="Dr. Pratheesh P. Gopinath" />


<meta name="date" content="2022-01-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="uniformity-trials.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">LECTURE NOTES</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#design-of-experiments"><i class="fa fa-check"></i><b>1.1</b> Design of experiments</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#a-simple-example"><i class="fa fa-check"></i><b>1.2</b> A simple example</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#importance-of-doe"><i class="fa fa-check"></i><b>1.3</b> Importance of DoE</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#characteristics-of-a-good-design"><i class="fa fa-check"></i><b>1.4</b> Characteristics of a good design</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#brief-history"><i class="fa fa-check"></i><b>1.5</b> Brief history</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#some-terms-involved"><i class="fa fa-check"></i><b>1.6</b> Some terms involved</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#treatments"><i class="fa fa-check"></i><b>1.6.1</b> Treatments</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#control"><i class="fa fa-check"></i><b>1.6.2</b> Control</a></li>
<li class="chapter" data-level="1.6.3" data-path="introduction.html"><a href="introduction.html#experimental-units"><i class="fa fa-check"></i><b>1.6.3</b> Experimental units</a></li>
<li class="chapter" data-level="1.6.4" data-path="introduction.html"><a href="introduction.html#response"><i class="fa fa-check"></i><b>1.6.4</b> Response</a></li>
<li class="chapter" data-level="1.6.5" data-path="introduction.html"><a href="introduction.html#factors"><i class="fa fa-check"></i><b>1.6.5</b> Factors</a></li>
<li class="chapter" data-level="1.6.6" data-path="introduction.html"><a href="introduction.html#factor-levels"><i class="fa fa-check"></i><b>1.6.6</b> Factor levels</a></li>
<li class="chapter" data-level="1.6.7" data-path="introduction.html"><a href="introduction.html#observational-unit"><i class="fa fa-check"></i><b>1.6.7</b> Observational Unit</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#experimental-error"><i class="fa fa-check"></i><b>1.7</b> Experimental error</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#basic-principles-of-design"><i class="fa fa-check"></i><b>1.8</b> Basic principles of design</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="introduction.html"><a href="introduction.html#randomization"><i class="fa fa-check"></i><b>1.8.1</b> <strong>Randomization</strong></a></li>
<li class="chapter" data-level="1.8.2" data-path="introduction.html"><a href="introduction.html#replication"><i class="fa fa-check"></i><b>1.8.2</b> <strong>Replication</strong></a></li>
<li class="chapter" data-level="1.8.3" data-path="introduction.html"><a href="introduction.html#local-control-error-control"><i class="fa fa-check"></i><b>1.8.3</b> <strong>Local control</strong> (error control)</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#other-methods-of-error-control"><i class="fa fa-check"></i><b>1.9</b> Other methods of error control</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="introduction.html"><a href="introduction.html#proper-plot-technique"><i class="fa fa-check"></i><b>1.9.1</b> Proper Plot Technique</a></li>
<li class="chapter" data-level="1.9.2" data-path="introduction.html"><a href="introduction.html#data-analysis"><i class="fa fa-check"></i><b>1.9.2</b> Data Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="uniformity-trials.html"><a href="uniformity-trials.html"><i class="fa fa-check"></i><b>2</b> Uniformity trials</a>
<ul>
<li class="chapter" data-level="2.1" data-path="uniformity-trials.html"><a href="uniformity-trials.html#how-uniformity-trial-is-performed"><i class="fa fa-check"></i><b>2.1</b> How uniformity trial is performed</a></li>
<li class="chapter" data-level="2.2" data-path="uniformity-trials.html"><a href="uniformity-trials.html#fertility-contour-map"><i class="fa fa-check"></i><b>2.2</b> Fertility Contour Map</a></li>
<li class="chapter" data-level="2.3" data-path="uniformity-trials.html"><a href="uniformity-trials.html#serial-correlation"><i class="fa fa-check"></i><b>2.3</b> Serial Correlation</a></li>
<li class="chapter" data-level="2.4" data-path="uniformity-trials.html"><a href="uniformity-trials.html#mean-square-between-strips"><i class="fa fa-check"></i><b>2.4</b> Mean square between strips</a></li>
<li class="chapter" data-level="2.5" data-path="uniformity-trials.html"><a href="uniformity-trials.html#fairfield-smiths-variance-law"><i class="fa fa-check"></i><b>2.5</b> Fairfield Smith’s Variance Law</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="uniformity-trials.html"><a href="uniformity-trials.html#smith"><i class="fa fa-check"></i><b>2.5.1</b> Smith’s index of soil heterogeneity</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="uniformity-trials.html"><a href="uniformity-trials.html#mcm"><i class="fa fa-check"></i><b>2.6</b> Maximum Curvature Method</a></li>
<li class="chapter" data-level="2.7" data-path="uniformity-trials.html"><a href="uniformity-trials.html#uniformity-trial-explained"><i class="fa fa-check"></i><b>2.7</b> Uniformity trial explained</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="uniformity-trials.html"><a href="uniformity-trials.html#fertility-contour-map-1"><i class="fa fa-check"></i><b>2.7.1</b> Fertility contour map</a></li>
<li class="chapter" data-level="2.7.2" data-path="uniformity-trials.html"><a href="uniformity-trials.html#serial-correlation-1"><i class="fa fa-check"></i><b>2.7.2</b> Serial Correlation</a></li>
<li class="chapter" data-level="2.7.3" data-path="uniformity-trials.html"><a href="uniformity-trials.html#mean-square-between-strips-1"><i class="fa fa-check"></i><b>2.7.3</b> Mean square between strips</a></li>
<li class="chapter" data-level="2.7.4" data-path="uniformity-trials.html"><a href="uniformity-trials.html#smiths-index-of-soil-heterogeneity"><i class="fa fa-check"></i><b>2.7.4</b> Smith’s index of soil heterogeneity</a></li>
<li class="chapter" data-level="2.7.5" data-path="uniformity-trials.html"><a href="uniformity-trials.html#maximum-curvature-method"><i class="fa fa-check"></i><b>2.7.5</b> Maximum Curvature Method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#null-hypothesis-in-anova"><i class="fa fa-check"></i><b>3.1</b> Null hypothesis in ANOVA</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>3.2</b> Degrees of freedom</a></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#mean-squares"><i class="fa fa-check"></i><b>3.3</b> Mean squares</a></li>
<li class="chapter" data-level="3.4" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#test-statistic-f"><i class="fa fa-check"></i><b>3.4</b> Test Statistic F</a></li>
<li class="chapter" data-level="3.5" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#assumptions-of-anova"><i class="fa fa-check"></i><b>3.5</b> Assumptions of ANOVA</a></li>
<li class="chapter" data-level="3.6" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#types-of-anova"><i class="fa fa-check"></i><b>3.6</b> Types of ANOVA</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>3.6.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="3.6.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#two-way-anova"><i class="fa fa-check"></i><b>3.6.2</b> Two-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#models-under-anova"><i class="fa fa-check"></i><b>3.7</b> Models under ANOVA</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#fix"><i class="fa fa-check"></i><b>3.7.1</b> Fixed effects model</a></li>
<li class="chapter" data-level="3.7.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#random-effects-model"><i class="fa fa-check"></i><b>3.7.2</b> Random effects model</a></li>
<li class="chapter" data-level="3.7.3" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#mixed-effects-model"><i class="fa fa-check"></i><b>3.7.3</b> Mixed effects model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>4</b> References</a></li>
<li class="divider"></li>
<li><a href="https://sites.google.com/view/kau-melon/home" target="blank">Published in MeLON</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">LECTURE NOTES OF STAT 512</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analysis-of-variance-anova" class="section level1" number="3">
<h1><span class="header-section-number">Lecture: 3</span> Analysis of Variance (ANOVA)</h1>
<p>Consider an example where three chemical fertilizers A, B, C are tested
on potted plants. Experimenter would like to identify, which among the
fertilizer among A, B and C gives the highest yield. Potted plants are
maintained in the same way; so that experimental conditions are
homogenous. Now after collecting yield data from the plants, you can
observe a variance <em>i</em>.<em>e</em>., the yield values are not same. Here, this
variation is caused by the treatment and experimental error. So, the
total observed variance = variance due to treatments + variance due to
error. So, in this example treatment and error can be considered as the
source of variation in the data. Basically, any experiment you perform
is a sample based on which you make generalization about the population.
Now, based on your experiment you want to test whether the means of
treatment A, B and C are significantly different considering that the
observed difference is not by chance taking in to account experimental
error variance.</p>
<p>Analysis of variance (ANOVA) is a statistical procedure used to analyze
the differences among means, where the observed total variance is
partitioned into components attributable to different sources of
variation. The logic behind is simple, if much of the variation comes
from the treatment, it is more likely that the mean of treatments is
different. This variation is compared with the experimental error
variance, larger the ratio of treatment variance to error variance, the
more likely that the groups have different means. The term "analysis of
variance" originates from how the analysis uses variances to determine
whether the means are different. ANOVA works by comparing the variance
of treatments (between group variance) to the error variance (within
group variance).</p>
<p>In short ANOVA is a statistical hypothesis test that determines whether
the means of at least two populations are different. ANOVA was developed
by the statistician Sir Ronald A. Fisher.</p>
<div id="null-hypothesis-in-anova" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Null hypothesis in ANOVA</h2>
<p>Null hypothesis in ANOVA is that population means are equal, which is
denoted as H<sub>0</sub>: µ<sub>1</sub> = µ<sub>2</sub> =µ<sub>3</sub> = …., = µ<sub>k</sub> . Alternate
hypothesis is that atleast a pair of treatment are not equal, H<sub>1</sub>: µ<sub>i</sub> ≠ µ<sub>j</sub>, where <em>i</em> ≠ <em>j</em>; <em>i</em>, <em>j</em> = 1,2, …, k. Where µ<sub>1</sub>, µ<sub>2</sub>, µ<sub>3</sub>, …, µ<sub>k</sub> are <em>k</em> population means</p>
</div>
<div id="degrees-of-freedom" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Degrees of freedom</h2>
<p>Before proceeding, it is important to understand the concept of degrees
of freedom. Degrees of freedom can be defined as the number of
independent observations that are free to vary.</p>
<p>Consider a simple example, you have 7 hats and you want to wear a
different hat every day of the week. On the first day, you can wear any
of the 7 hats. On the second day, you can choose from the 6 remaining
hats, on day 3 you can choose from 5 hats, and so on. When day 6 rolls
around, you still have a choice between 2 hats that you haven’t worn yet
that week. But after you choose your hat for day 6, you have no choice
for the hat that you wear on Day 7. You must wear the one remaining hat.
You had 7-1 = 6 days of “hat” freedom—in which the hat you wore could
vary!</p>
<p>Degrees of freedom can also be defined as the number of independent
values, which were included into calculation of an estimate. An estimate
is a single number that expresses some property of a population from a
sample. It can be mean, median, standard deviation, or variance that is
calculated from a sample. And there are independent values (or
observations) that went into formula calculation. The quantity of these
values is called “degrees of freedom.”</p>
<p>Consider three observations 6, x and 9. Here x is unknown and suppose we
know the mean is 6. Then we can say x is exactly equal to 3, because
mean is 6. Here two values are free to vary but the third value depends
on other two under the constraint that their mean should be 6. <em>i</em>.<em>e</em>.
if other two values are changed third value will also change.</p>
<p>Now consider the height of 7 students</p>
<p>164, 173, 158, 179, 168, 187, 167.</p>
<p>Mean: 170.85</p>
<p>We can find standard deviation using two formulas</p>
<p>SD= <span class="math inline">\(\frac{\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2}}{n}\)</span>, where
n is the number of observations</p>
<p>Here SD = 9</p>
<p>SD= <span class="math inline">\(\frac{\sum_{}^{}\left( x_{i} - \overline{x} \right)^{2}}{n - 1}\)</span>,
where n-1 is the degrees of freedom</p>
<p>Here SD = 9.72</p>
<p>It is easy to notice that when we divide by degrees of freedom, we make
our estimate of standard deviation greater than if we were diving only
by sample size. But why do we need to make it greater? As we’ve already
calculated the mean, we don’t have to use all the data in order to
estimate the standard deviation. It does not depend on each piece of
information, and the last observation does not contribute to the
standard deviation. So, if we don’t delete this redundant data, then we
underestimate the standard deviation of population from sample data. So here using the degrees of freedom in the denominator provides an unbiased estimate of population standard deviation.</p>
<p>Degrees of freedom also define the probability distributions for the
test statistics of various hypothesis tests. For example, hypothesis
tests use the t-distribution, F-distribution, and the chi-square
distribution to determine statistical significance. Each of these
probability distributions is a family of distributions where the DF
define the shape. Hypothesis tests use these distributions to make
decisions on null hypothesis.</p>
</div>
<div id="mean-squares" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Mean squares</h2>
<p>The sum of squares is the sum of the square of difference of each
observation from mean. That is Sum of squares
=<span class="math inline">\(\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}\)</span>. Where, <em>i</em>
=1, 2, …, <em>n</em>, mean <span class="math inline">\(\overline{x} = \frac{\sum_{i = 1}^{n}x_{i}}{n}\)</span>.
Sum of squares generates a measure of variability. In One-way ANOVA we
calculate sum of squares of all observation to get measure of total
variability along with within group and between group sum of squares,
that gives idea on with in (error) and between group (between
treatments) variability respectively. Mean sum of squares or mean
squares are obtained by dividing sum of squares by corresponding degrees
of freedom. Mean square provides unbiassed estimate of variance. For
example, in ANOVA error mean square (MSE) given by
<span class="math inline">\(\frac{\text{with in group sum of squares}}{\text{error degrees of freedom}}\)</span>
provides unbiased estimate of error variance</p>
</div>
<div id="test-statistic-f" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Test Statistic F</h2>
<p>Any function of sample values is known as a statistic. For example,
sample mean, sample variance, sum of all sample values are statistic,
because these are all some functions of sample values. If a statistic is
used to test a hypothesis, then it is known as test statistic. Examples
of test statistic are t, F, χ<sup>2</sup> etc. The test statistic used in ANOVA
is F.</p>
<p>F-statistic is the ratio of two variances and it was named after Sir
Ronald A. Fisher. It is proved that when null hypothesis H<sub>0</sub>: µ<sub>1</sub> =
µ<sub>2</sub> =µ<sub>3</sub> = …., = µ<sub>k</sub> is true the ratio of mean square treatment and
mean square error follows F distribution. In general, if your calculated
F value in ANOVA is larger than your F critical value, you can reject
the null hypothesis.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fdist"></span>
<img src="images/fdist.png" alt="Distribution F under different degrees of freedom" width="60%" />
<p class="caption">
Figure 3.1: Distribution F under different degrees of freedom
</p>
</div>
</div>
<div id="assumptions-of-anova" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Assumptions of ANOVA</h2>
<ul>
<li><p>Observations under each treatment group is drawn randomly from a normally distributed population</p></li>
<li><p>All the populations from which observations are drawn have a common variance :- Homogeneity of variance</p></li>
<li><p>All the samples are drawn independently of each other</p></li>
<li><p>Treatment and environmental effects are additive</p></li>
</ul>
<blockquote>
<p>As a result of above assumptions. The experimental errors are independent and identically distributed (iid) with a Normal distribution of mean 0 and variance σ<sup>2</sup>. In other word we can say <span class="math inline">\(e_{i}\)</span> <span class="math inline">\(\sim iid\ N(0,\sigma^{2})\)</span>.</p>
</blockquote>
</div>
<div id="types-of-anova" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Types of ANOVA</h2>
<p>Based on the model used and sources of variation studied ANOVA can be classified into following types</p>
<ul>
<li>One-way ANOVA<br />
</li>
<li>Two-way ANOVA<br />
</li>
<li><em>m</em>-way ANOVA</li>
</ul>
<div id="one-way-anova" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> One-way ANOVA</h3>
<p>The simplest type of analysis of variance is known as one way analysis of variance, in which only one source of variation or factor of interest is controlled and its effect on the elementary units is observed. See the example in section <a href="analysis-of-variance-anova.html#fix">3.7.1</a> is an example where one-way ANOVA can be employed. Here only one source of variation is assumed to be causing variance other than error that is field.
One -way ANOVA model is:<br />
<span class="math display">\[Y_{\text{ij}} = \mu + \tau_{i} + e_{\text{ij}}\]</span><br />
Where <em>i</em> = 1,2, …, <em>t</em> and <em>j</em> =1,2, …, <em>r</em>. <span class="math inline">\(Y_{\text{ij}}\)</span> is the observed value of <em>i</em><sup>th</sup>
treatment from <em>j</em><sup>th</sup> replication, <span class="math inline">\(\tau_{i}\)</span> is the effect of <em>i</em><sup>th</sup> treatment. <span class="math inline">\(\mu\)</span> is the general
effect which is common for all treatments. <span class="math inline">\(e_{\text{ij}}\)</span> is the error
effects.<span class="math inline">\(e_{i}\)</span> <span class="math inline">\(\sim iid\ N(0,\sigma^{2})\)</span></p>
Consider an experiment with <em>v</em> treatments with <em>r</em> replications each. Observations are recorded as shown below.<br />

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:oneway"></span>
<img src="images/oneway.png" alt="One way classification of Data" width="60%" />
<p class="caption">
Figure 3.2: One way classification of Data
</p>
</div>
<p>ANOVA consists of partitioning the total variation in Y<sub>ij</sub> values
into variation due to treatments and variation caused by uncontrolled
factors (error variation). Therefore, we can write,</p>
<p>Variance of <em>Y</em><sub>ij</sub> =
<span class="math inline">\(\frac{1}{n}\sum_{i = 1}^{v}\sum_{j = 1}^{r}\left( Y_{\text{ij}} - \bar{Y} \right)^{2}\)</span>where <em>n</em> =
<em>v</em> x <em>r</em>, overall mean <span class="math inline">\(\bar{Y} = \frac{G}{n}\)</span></p>
<p>Total Sum of Squares = <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}}^{2} - \frac{G^{2}}{n}\)</span>; where
<span class="math inline">\(\frac{G^{2}}{n}\)</span> is known as the correction factor (C.F.).</p>
<div id="proof" class="section level4" number="3.6.1.1">
<h4><span class="header-section-number">3.6.1.1</span> Proof</h4>
<p>= <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r}\left( Y_{\text{ij}} - \bar{Y} \right)^{2}\)</span><br />
= <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r}\left( Y_{\text{ij}}^{2} - 2Y_{\text{ij}}\bar{Y} + {\bar{Y}}^{2} \right)\)</span><br />
= <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r}\left( Y_{\text{ij}}^{2} - 2n{\bar{Y}}^{2} + n{\bar{Y}}^{2} \right)\)</span></p>
<p>= <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r}\left( Y_{\text{ij}}^{2} - n{\bar{Y}}^{2} \right)\)</span></p>
<p>= <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}}^{2} - n\left( \frac{\sum_{i = 1}^{v}\sum_{j = 1} Y_{\text{ij}}}{n} \right)^{2},\)</span>
denote <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}} = G\)</span><br />
Total Sum of Squares = <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}}^{2} - \frac{G^{2}}{n}\)</span></p>
<p>The Total Sum of Squares is partitioned into Sum of Squares due to Treatments and Sum of Squares due to Error.</p>
</div>
<div id="proof-1" class="section level4" number="3.6.1.2">
<h4><span class="header-section-number">3.6.1.2</span> Proof</h4>
<p><span class="math display">\[\sum_{i = 1}^{v}{\sum_{j = 1}^{r}\left( Y_{\text{ij}} - \overline{Y} \right)^{2}} = \sum_{i = 1}^{v}{\sum_{j = 1}^{r}\left( Y_{\text{ij}} - {\overline{Y}}_{i} + {\overline{Y}}_{i} - \overline{Y} \right)^{2}}\]</span></p>
<p><span class="math display">\[= \sum_{i = 1}^{v}{\sum_{j = 1}^{r}\left( \left( Y_{\text{ij}} - {\overline{Y}}_{i} \right)^{2} + \left( {\overline{Y}}_{i} - \overline{Y} \right)^{2} + 2\left( Y_{\text{ij}} - {\overline{Y}}_{i} \right)\left( {\overline{Y}}_{i} - \overline{Y} \right) \right)}\]</span></p>
<p><span class="math display">\[= \sum_{i = 1}^{v}{\sum_{j = 1}^{r}{\left( Y_{\text{ij}} - {\overline{Y}}_{i} \right)^{2} +}}\sum_{i = 1}^{v}{\sum_{j = 1}^{r}{\left( {\overline{Y}}_{i} - \overline{Y} \right)^{2} + 2\sum_{i = 1}^{v}{\sum_{j = 1}^{r}{\left( Y_{\text{ij}} - {\overline{Y}}_{i} \right)\left( {\overline{Y}}_{i} - \overline{Y} \right)}}}}\]</span></p>
<p>Let
<span class="math inline">\(\left( Y_{\text{ij}} - {\overline{Y}}_{i} \right)^{2} = e_{\text{ij}}^{2}\)</span>,
<span class="math inline">\(\sum_{i = 1}^{v}{\sum_{j = 1}^{r}e_{\text{ij}}} = 0\)</span></p>
<p><span class="math display">\[= \sum_{i = 1}^{v}{\sum_{j = 1}^{r}{{e_{\text{ij}}}^{2} +}}\sum_{i = 1}^{v}{\sum_{j = 1}^{r}{\left( {\overline{Y}}_{i} - \overline{Y} \right)^{2} + 2\sum_{i = 1}^{v}{\sum_{j = 1}^{r}{e_{\text{ij}}\left( {\overline{Y}}_{i} - \overline{Y} \right)}}}}\]</span></p>
<p><span class="math inline">\(\sum_{i = 1}^{v}{\sum_{j = 1}^{r}{e_{\text{ij}}\left( {\overline{Y}}_{i} - \overline{Y} \right)}} = 0\)</span>,
since the sum of the weighted residuals is zero, then the above equation
will be</p>
<p><span class="math display">\[= \sum_{i = 1}^{v}{\sum_{j = 1}^{r}{{e_{\text{ij}}}^{2} +}}\sum_{i = 1}^{v}{\sum_{j = 1}^{r}\left( {\overline{Y}}_{i} - \overline{Y} \right)^{2}}\]</span></p>
<p>Total Sum of Square = with in group sum of square + between group sum of
square</p>
<blockquote>
<p>Total Sum of Square = Error sum of square + Treatment Sum of Square</p>
</blockquote>
<p>Let us denote the treatment totals as T<sub>1,</sub> T<sub>2, ….,</sub>T<em><sub>V</sub></em> <em>i</em>.<em>e</em> <span class="math inline">\({T}_{i}{\ =\ }\sum_{j = 1}^{r} Y_{\text{ij}}\)</span> so that
<span class="math inline">\(T_{1}{\ +\ }{T}_{2}{\ +\ }\text{T}_{3}{\ +\ }{T}_{n}\text{ }\text{……}{+\ }{T}_{v}{\ =\ }\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}} = G\)</span></p>
<p>Treatment Sum of Squares, TSS =
<span class="math inline">\(\frac{\sum_{i = 1}^{v}\text{T}\text{i}^{2}}{r} - \frac{G^{2}}{n}\)</span>.</p>
</div>
<div id="oneway" class="section level4" number="3.6.1.3">
<h4><span class="header-section-number">3.6.1.3</span> Calculations for One-way ANOVA</h4>
<p>Total Sum of Square (Total SS) = <span class="math inline">\(\sum_{i = 1}^{v}\sum_{j = 1}^{r} Y_{\text{ij}}^{2} - \text{C.F.}\)</span>
(square all the observations, sum it and correction factor is subtracted to get total sum of squares)</p>
<p>Treatment Sum of Squares (TSS) = <span class="math inline">\(\frac{\sum_{i = 1}^{v}\text{T}\text{i}^{2}}{r} - \text{C.F.}\)</span>.
(square all the treatment totals, sum it and correction factor is subtracted to get treatment sum of squares )</p>
<p>Error Sum of Squares (ESS)= Total SS – TSS</p>
<p>Correction factor (C.F.) = <span class="math inline">\(\frac{G^{2}}{n}\)</span>, where <span class="math inline">\(G\)</span> = Grand Total of all observations.</p>
<p>Mean sum of squares is the sum of squares divided by corresponding
degrees of freedoms (d.f.).</p>
<p>Error degrees of freedom = Total degrees of freedom – treatment degrees of freedom.</p>
<p>Error d.f.= <span class="math inline">\(vr - 1 - \left( v - 1 \right) = vr - 1 - v + 1 = vr - v = v(r - 1)\)</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:onewayanova"></span>
<img src="images/onewayanova.png" alt="One-way ANOVA table" width="90%" />
<p class="caption">
Figure 3.3: One-way ANOVA table
</p>
</div>
<p>Here F ~ F <sub>(v-1), v(r-1)</sub></p>
<p>MSE is an estimate of error variance σ<sup>2</sup> and
<span class="math inline">\(\sqrt{\frac{\text{MSE}}{r}}\)</span> is the standard error of a treatment mean.</p>
</div>
</div>
<div id="two-way-anova" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Two-way ANOVA</h3>
</div>
</div>
<div id="models-under-anova" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Models under ANOVA</h2>
<p>Analysis of variance is based on a linear statistical model. This linear model may be either</p>
<ul>
<li><p>Fixed effects model</p></li>
<li><p>Random effects model</p></li>
<li><p>Mixed effects model</p></li>
</ul>
<div id="fix" class="section level3" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Fixed effects model</h3>
<p>Fixed effects model is a statistical model in which the model parameters
are fixed or non-random quantities. In using fixed effect model in
agricultural experiments, we assume treatment effect are unknown
constants</p>
<p>Fixed effects model can be explained using an example. Consider an
experiment where experimenter wants to know whether three fields had any
impact on the yield of a particular strain of wheat. Observations where
taken from 12 plots from each fields (replication). The AOV (Analysis of
Variance) model is</p>
<p><span class="math inline">\(Y_{\text{ij}} = \mu + \tau_{i} + e_{\text{ij}}\)</span></p>
<p>Where <em>i</em> = 1,2, …, <em>t</em> and <em>j</em> =1,2, …, <em>r</em>. Here in our example
<em>t</em> =3 and <em>r</em> =12. <span class="math inline">\(Y_{\text{ij}}\)</span> is the observed value of <em>i</em><sup>th</sup>
field from <em>j</em><sup>th</sup> plot, <span class="math inline">\(\tau_{i}\)</span> is the effect of <em>i</em><sup>th</sup> treatment,
which is considered to be an unknown constant. <span class="math inline">\(\mu\)</span> is the general
effect which is common for all treatments. <span class="math inline">\(e_{\text{ij}}\)</span> is the error
effects, which are independently and normally distributed with mean 0
and constant variance σ<sup>2</sup>. In this model, field is a “fixed effect.”
Along with <span class="math inline">\(\mu\)</span>, the fixed parameters <span class="math inline">\(\tau_{1}\)</span>,<span class="math inline">\(\tau_{2}\)</span> and
<span class="math inline">\(\tau_{3}\)</span> are the quantities of interest. Using this model,
experimenter can make decisions only on the treatment (field) tested.</p>
</div>
<div id="random-effects-model" class="section level3" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Random effects model</h3>
<p>A random effects model, also called as a variance components model, is a
statistical model where the model parameters are random variables.
Consider the example above in of wheat fields, if a random effect model
is used then, fields are assumed to be randomly sampled from a
population of fields in that area and the AOV (Analysis of Variance)
model is</p>
<p><span class="math inline">\(Y_{\text{ij}} = \mu + \tau_{i} + e_{\text{ij}}\)</span></p>
<p>Where <em>i</em> = 1,2, …, <em>t</em> and <em>j</em> =1,2, …, <em>r</em>. Here <span class="math inline">\(\tau_{i}\)</span> is
considered as a random variable,
<span class="math inline">\(\tau_{i}\sim N(0,\ \sigma_{\tau}^{2})\)</span>; and
<span class="math inline">\(e_{ij}\sim N(0,\ \sigma^{2})\)</span>. In this model, field is a “random
effect.” The statistical model describes the whole ensemble of possible
repetitions of the experiment in the region from which the fields were
selected. Experimenter could make generalisations on all the fields in
that particular region based on his experiment. One important
consequence of random effects is that the responses (<span class="math inline">\(Y_{\text{ij}}\)</span>'s)
are no longer independent. The random <span class="math inline">\(\tau_{i}\)</span>'s induce correlations
among the responses. The responses jointly have a multivariate normal
distribution.</p>
</div>
<div id="mixed-effects-model" class="section level3" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Mixed effects model</h3>
<p>A mixed model, mixed-effects model or mixed error-component model is a
statistical model containing both fixed effects and random effects.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="uniformity-trials.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
