[["index.html", "LECTURE NOTES OF STAT 512 Welcome", " LECTURE NOTES OF STAT 512 Dr. Pratheesh P. Gopinath 2022-01-30 Welcome Welcome to the book LECTURE NOTES ON EXPERIMENTAL DESIGNS. "],["preface.html", "Preface", " Preface Note: This book is published in MeLoN (Module for e-Learning &amp; Online Notes) . The online version of this book is free to read here. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. If you have any feedback, please feel free to contact Dr.Pratheesh P. Gopinath. E-mail: pratheesh.pg@kau.in Thank you! This book is a collection of all lecture notes covering the syllabus of EXPERIMENTAL DESIGNS, which is a common course of statistics in Post graduate programmes in Agriculture under Kerala Agricultural University Syllabus Objective This course is meant for students of agricultural and animal sciences other than Agricultural Statistics. Designing an experiment is an integrated component of research in almost all sciences. The students would be exposed to concepts of Design of Experiments so as to enable them to understand the concepts involved in planning, designing their experiments and analysis of experimental data. Theory UNIT I Need for designing of experiments, characteristics of a good design. Basic principles of designs - randomization, replication and local control. UNIT II Uniformity trials, size and shape of plots and blocks; Analysis of variance; Completely randomized design, randomized block design and Latin square design. UNIT III Factorial experiments, (symmetrical as well as asymmetrical). orthogonality and partitioning of degrees of freedom, Confounding in symmetrical factorial experiments, Factorial experiments with control treatment. UNIT IV Split plot and strip plot designs; Analysis of covariance and missing plot techniques in randomized block and Latin square designs; Transformations, crossover designs, balanced incomplete block design, Lattice design, Response surfaces. UNIT V Bioassays- direct and indirect, potency estimation. Practical Uniformity trial data analysis, formation of plots and blocks, Fairfield Smith Law; Analysis of data obtained from CRD, RBD, LSD; Analysis of factorial experiments without and with confounding; Analysis with missing data; Split plot and strip plot designs; Transformation of data; Fitting of response surfaces and Bioassays. "],["introduction.html", "Lecture: 1 Introduction 1.1 Design of experiments 1.2 A simple example 1.3 Importance of DoE 1.4 Characteristics of a good design 1.5 Brief history 1.6 Some terms involved 1.7 Experimental error 1.8 Basic principles of design 1.9 Other methods of error control", " Lecture: 1 Introduction Need for designing of experiments, characteristics of a good design. Basic principles of designs - randomization, replication and local control 1.1 Design of experiments Design of Experiments is an integral component of agricultural research. A scientifically designed experiment is a valuable tool in advancement in gaining new knowledge and technology development. It is the effective use of the tools of statistical design of experiments that paved the way for the green revolution  these words of the father of green revolution in India, Dr. M.S. Swaminathan, itself shows how important is Design and analysis of experiments as well as statistical science is for agricultural experiments. A carefully designed experiment is able to answer all the queries of a researcher with accuracy and reliability with efficient use of available resources of the experimenters. Thus, for successful experimentation, it is highly desirable that scientists and researchers of scientific disciplines, including agricultural sciences, understand the basic principles of designing an experiment and analysis of resultant data from the completed experiment. It may be emphasized that a researcher should always consult a statistician before, during and after experimentation, if he is not convinced enough about using a design for his experiment or an analysis technique for his data. Any scientific investigation involves formulation of certain assertions (or hypotheses) whose validity is examined through the data generated from an experiment conducted for the purpose. The term experimentis defined as the systematic procedure carried out under controlled conditions in order to discover an unknown effect, to test or establish a hypothesis, or to illustrate a known effect. Experiments can be designed in many different ways to collect information. Design of experiments (DOE) is a systematic method to determine the relationship between factors affecting a process and the output of that process. In other words, it is used to find cause-and-effect relationships. DOE is a structured approach for conducting experiments. Mainly aims at Validity Reliability Replicability Optimality 1.2 A simple example Suppose you want to know, which of the 3 organic manures (Poultry manure, Cow-dung, Coir-pith compost) is good for getting high yield. Figure 1.1: Poultry manure, cow dung and coirpith compost You have decided to conduct an experiment. Consider you as a layman with no knowledge in design of experiments. So, you have selected 3 potted plants for the experiment. 3 organic manures are applied to the potted plants. Figure 1.2: Treatments given to potted plants as shown So now after the experiment you got yield from each plant as shown below. 5 kg for poultry manure, 4 kg for cow dung and 3 kg for coir-pith compost. Figure 1.3: Yield observed from the plants So, based on your experiment, can you say the poultry manure is the best? What if somebody repeats this experiment somewhere and the results are different? What about the variance due to experimental error? What if the experimenter wants to show that poultry manure is the best? So he has allotted healthy plant to poultry manure. Can an experiment like this has validity? Can we make a conclusion from this experiment? Answer to this question gives the importance of proper designing of experiments. Nobody in the scientific fraternity is going to accept your above experiment. Your experiment has validity only if its validity is proved by statistical theories. All these issues can be well taken care off by proper designing of experiments. After discussing the basic principles of design, it will be shown, how the above experiment looks like after proper designing. Design of experiment means how to design an experiment. In the sense that how the observations or measurements should be obtained to answer a query in a valid, efficient and economical way. The designing of experiment and the analysis of obtained data are inseparable. If the experiment is designed properly keeping in mind the question, then the data generated is valid and proper analysis of data provides the valid statistical inferences. If the experiment is not well designed, the validity of the statistical inferences is questionable and may be invalid. 1.3 Importance of DoE Reduce, control and provides an estimate of the experimental Error Gives a structured approach It reduce cost of experiment with considerable reliability Produces statistically valid results Allows to accommodate changes Reduce complexity Improves accountability 1.4 Characteristics of a good design Provides unbiased estimates of the factor effects and associated uncertainties Enables the experimenter to detect important differences Includes the plan for analysis and reporting of the results Gives results that are easy to interpret Permits conclusions that have wide validity Minimal resource usage Is as simple as possible Statistical design of experiments refers to the process of planning the experiment so that appropriate data will be collected and analyzed by statistical methods, resulting in valid and objective conclusions. The statistical approach to experimental design is necessary if we wish to draw meaningful conclusions from the data. When the problem involves data that are subject to experimental errors, statistical methods are the only objective approach to analysis. Creation of controlled conditions is the main characteristic feature of experimentation and DOE specifies the nature of control over the operations in experiments. Proper designing ensures that the assumptions required for appropriate interpretations of data are satisfied thus increasing the accuracy and sensitivity of results. There are two aspects to any experimental problem: the design of the experiment and the statistical analysis of the data. These two subjects are closely related because the method of analysis depends directly on the design employed. Figure 1.4: DoE and Statistical analysis 1.5 Brief history The statistical principles underlying design of experiments were pioneered by R. A. Fisher in the 1920s and 1930s at Rothamsted Experimental Station, an agricultural research station around fourty kilometres north of London. Fisher had shown the way on how to draw valid conclusions from field experiments where nuisance variables such as temperature, soil conditions, and rainfall are present. He introduced the concept of analysis of variance (ANOVA) for partitioning the variation present in data (a) due to attributable factors, and (b) due to chance factors. The methodologies he and his colleague Frank Yates developed are now widely used. Their methodologies have a profound impact on agricultural sciences research. Though the experimental design was initially introduced in an agricultural context, the method has been applied successfully in the industry since the 1940s. George Box and his co-workers developed experimental design procedures for optimizing chemical processes, particularly response surface designs for chemical and process industries. Recently, experimental designs are also being used in clinical trials. This evolved in the 1960s when medical advances were previously based on unreliable data. For example, doctors used to examine a few patients and publish papers based on such data. The biases resulting from these kinds of studies became known. This led to a move toward making the randomized double-blind clinical trial the standard for approval of any new product, medical device, or procedure. The scientific application of the valid designing and analysis following proper statistical methods became very important in clinical trials. More recently the experimental design techniques have started gaining popularity in the area of computer-aided design and engineering using computer/simulation models including applications in manufacturing industries. 1.6 Some terms involved 1.6.1 Treatments The term treatments is used to denote the different objects, methods or processes among which comparison is made. For example, if an experimenter wants to identify which among the objects/methods/process is the best based on an experiment; then this objects/methods/process is called the treatment. More clearly anything that you are about to compare in an experiment is known as the treatment. Some examples of treatments are different kinds of fertilizer in agronomic experiments, different irrigation methods or levels of irrigation, different fungicides in pest management experiments , doses of different drugs or chemicals in laboratory experiments, different varieties of crops, different pesticides, grazing systems for animals, different tree species in agro-forestry experiments, different concentrations of a solute in chemical experiments etc. 1.6.2 Control A control treatment is a standard treatment that is used as a baseline or basis of comparison for the other treatments. This control treatment might be the treatment which is currently in use, or it might be a no treatment at all. For example, a study of new pesticides could use a standard pesticide as a control treatment, or an experiment involving fertilizers may have one treatment as no fertilizers at all. In clinical trials, a control treatment is generally a placebo. 1.6.3 Experimental units Experimental units are the subjects or objects on which the treatments are applied. For example, plots of land receiving fertilizer, groups of animals receiving different feeds, or batches of chemicals receiving different temperatures, pots in glasshouse experiments, Petri dishes or tissues to culture bacteria or micro-organisms in laboratory experiments, etc 1.6.4 Response Responses are measurable outcomes, which are observed after applying a treatment to an experimental unit. Alternatively, the response is what we measure to find out what happened in the experiment. In an experiment, there may be more than one response. Some examples of responses are grain yield or straw yield, nitrogen content in plants or biomass of plants, quality parameters of the produce, percentage of plants infested by disease, weight gain by animals, etc. 1.6.5 Factors Factors are the variables whose influence on a response variable is being studied in the experiment. If only one factor is being studied in an experiment then such an experiment is called a single factor experiment. If more than one factor is being studied simultaneously in an experiment, then such an experiment is called multi-factor or factorial experiment. The term factor is commonly used in the case of factorial experiments. For example, temperature and concentration of chemicals in a chemical experiment are two factors, Nitrogen, Phosphorus and Potassium fertilizers are three factors in an agronomic experiment.Dose and time of application of a chemical formulation are two factors in a laboratory experiment. 1.6.6 Factor levels The term factor levels or a simply levels is used to denote the values or settings that a factor takes in a factorial experiment. For example, doses of a nitrogenous fertilizer as 0 kg/ha, 30 kg/ ha, 80 kg/ha are three levels of the factor fertilizer. 10%, 20%, 30%, 40% concentration of a solute in a solution are four levels of the factor solute in a laboratory experiment. Presence of polythene sheet on the surface of soil or its absence could be two levels of factor management practice in water management study. 1.6.7 Observational Unit An observational unit is a unit on which the response variables are measured. Observational units are often the same as experimental units, but this may not be true always. The mistake of confusing observational unit with experimental unit leads to pseudo-replication as discussed in a paper by (Hurlbert 1984). Consider an experiment to investigate the effects of ultraviolet (UV) levels on the growth of smolt. The experiment is conducted in two tanks where one tank receives high levels of UV light and the other tank receives no UV light. Fish are placed in each tank and at the end of the experiment growths of the individual fish are measured. In this experiment, the tanks are the experimental units but the observational units are the smolts. The treatments, presence and absence of UV light, are applied to the tanks and not to individual fish but a whole group of fish are simultaneously exposed to the UV radiation. Here any tank effect is completely confounded with the treatment effect and cannot be separated. Another example is that inorganic fertilizers are applied to plots in a field containing some plants. At the time of harvest, all the plants in the plot are not harvested. Only a sample of plants is harvested. In this case once again the plot is the experimental unit to which fertilizers are applied but the observational units are the plants sampled. 1.7 Experimental error To explain experimental error consider the example given by (Gomez and Gomez 1984). Consider a plant breeder who wishes to compare the yield of a new rice variety A to that of a standard variety B of known and tested properties. He lays out two plots of equal size, side by side, and sows one to variety A and the other to variety B. Grain yield for each plot is then measured and the variety with higher yield is judged as better. Despite the simplicity and common-sense appeal of the procedure just outlined, it has one important flaw. It presumes that any difference between the yields of the two plots is caused by the varieties and nothing else. This certainly is not true. Even if the same variety were planted on both plots, the yield would differ. Other factors, such as soil fertility, moisture, and damage by insects, diseases, and birds also affect rice yields. Because these other factors affect yields, a satisfactory evaluation of the two varieties must involve a procedure that can separate varietal difference from other sources of variation. That is, the plant breeder must be able to design an experiment that allows him to decide whether the difference observed is caused by varietal difference or by other factors. The logic behind the decision is simple. Two rice varieties planted in two adjacent plots will be considered different in their yielding ability only if the observed yield difference is larger than that expected, if both plots were planted to the same variety. Hence, the researcher needs to know not only the yield difference between plots planted to different varieties, but also the yield difference between plots planted to the same variety. The difference among experimental plots treated alike is called experimental error. This error is the primary basis for deciding whether an observed difference is real or just due to chance. Clearly, every experiment must be designed to have a measure of the experimental error. Response from all experimental units receiving the same treatment may not be same even under similar conditions. These variations in responses may be due to various reasons. Other factors like heterogeneity of soil, climatic factors and genetic differences, etc also may cause variations (known as extraneous factors). Definition: The variations in response caused by extraneous factors are known as experimental error. Our aim of designing an experiment will be to minimize the experimental error. 1.8 Basic principles of design There are three basic principles of designing an experiment namely randomization, replication and local control (blocking). 1.8.1 Randomization Randomization means random assignment of conditions to study or treatments to the subjects or experimental units. The principle of randomization involves the allocation of treatment to experimental units at random to avoid any bias in the experiment resulting from the influence of some extraneous unknown factor that may affect the experiment. In the development of analysis of variance (ANOVA), we assume that the errors are random and independent. In turn, the observations also become random through randomization. The observations are independent and are identically distributed as normal variate is an important assumption in hypothesis testing problems involving test statistics F (Snedecors F) and t (Students t). This is the major purpose of randomization. Randomization forms the basis of a valid experiment but replication is also needed for the validity of the experiment. If the randomization process is such that every experimental unit has an equal chance of receiving each treatment, it is called complete randomization. Consider an example where suppose you want to randomly allot 3 treatments to 3 experimental units. How will you do this? It is very easy; just label all the units from 1 to 3. Make a lot of equal size labelling 1,2 and 3. Put these labels in a bowl pick it with eyes closed. Now if 1 comes; first treatment is alloted to 1st unit. This is a very simple technique of randomization. Random number tables or computer generated random numbers can also be used. Figure 1.5: Taking a lot from a bowl is also a procees of randomization 1.8.2 Replication In the replication principle, any treatment is repeated a number of times to obtain a valid and more reliable estimate than which is possible with one observation only. Replication provides an efficient way of increasing the precision of an experiment. The precision increases with the increase in the number of observations. Replication provides more observations when the same treatment is used, so it increases precision. Replication enables the experimenter to obtain a valid estimate of the experimental error. Estimate of experimental error permits statistical inference; for example, performing tests of significance or obtaining confidence interval, etc. If there is no replication, then the researcher would not be able to estimate the experimental error. And as will be seen in the later Chapters, it is against this estimated experimental error the null hypotheses are tested. Consider an example where two chemicals A and B are applied to a crop. The interest of study is to see how chemical influences the yield of the crop. In the experiment, there are four plots available and chemical A and B are applied to two plots each randomly as shown in Figure 1.6. The plots receiving the same chemical is expected to give the same response. Here each treatment is repeated 2 times; so, replication is 2. The difference gives the experimental error. Figure 1.6: Treatments alloted to four plots, replication of each treatment is 2 The results from the experiment is shown Figure 1.7. The yield in kg per plot is given in bracket. Figure 1.7: The yield in kg per plot is given in bracket In the experiment, the experimental error can be estimated as \\(\\frac{\\left( 6 - 8 \\right)^{2} + {(5 - 4)}^{2}}{2} = \\frac{4 + 1}{2} = 2.5\\); here the denominator 2 is the number of replications. This can be also calculated as the square of difference of observation from corresponding treatment mean, here the mean of A is \\(\\frac{6 + 8}{2} = 7\\); the mean of B is \\(\\frac{5 + 4}{2} = 4.5\\). The sum of the square of difference of each observation from treatment mean is taken as shown below \\(\\left( 6 - 7 \\right)^{2} + \\left( 8 - 7 \\right)^{2} + \\ \\left( 5 - 4.5 \\right)^{2} + \\ {(4 - 4.5)}^{2} = 2.5\\) Thus, replication helps to estimate experimental error. Increasing the size of the experiment or increasing the replication also helps to increase the precision of estimating the pairwise differences among the treatment effects. . Replication provides an efficient way of increasing the precision of an experiment. The precision increases with the increase in the number of observations. Replication provides more observations when the same treatment is used, so it increases precision. 1.8.3 Local control (error control) A good experiment incorporates all possible means of minimizing the experimental error; because ability to detect experimental error increases as the size of experimental error decreases. By putting experimental units that are as similar as possible together in the same group (commonly referred to as a block) and by assigning all treatments into each block separately and independently, variation among blocks can be measured and removed from experimental error. In field experiments where substantial variation within an experimental field can be expected, significant reduction in experimental error is usually achieved with the use of proper blocking. The replication is used with local control to reduce the experimental error. For example, if the experimental units are divided into different groups such that they are homogeneous within the blocks, then the variation among the blocks is eliminated and ideally, the error component will contain the variation due to the treatments only. This will, in turn, increase the efficiency. You have a field experiment with 4 treatments and 5 replications. Consider a field with fertility gradient from left to right as shown in figure 1.8. Figure 1.8: A field with fertility gradient from left to right Homogeneity can be achieved by dividing the field in to groups as shown in figure 1.9. Now each vertical strips can be considered as a block. Plots are formed with in each block, where each treatment is allotted randomly. Here randomization is performed with in blocks. You can see that in this example replication is equal to number of blocks, which is equal to 5. Randomization is achieved with in blocks. Local control is achieved by grouping treatments in homogeneous blocks, where fertilizer gradient is same. This is a typical example of Randomized Block Design (RBD), which will be discussed in chapter Figure 1.9: A field with fertility gradient from left to right 1.9 Other methods of error control 1.9.1 Proper Plot Technique It is essential that all other factors, which are not treatments should be maintained uniformly for all experimental units. For example, in field experiments, it is required that all other factors such as soil nutrients, solar energy, plant population, pest incidence, and an almost infinite number of other environmental factors are maintained uniformly for all plots in the experiment. This requirement is impossible to satisfy, however to ensure that variability among experimental plots is minimum, some important sources of variability are taken care off using a good plot technique. For field experiments with crops, some important sources of variability considered among plots treated alike are soil heterogeneity, competition effects, and mechanical errors. 1.9.2 Data Analysis Proper choice of data analysis helps in controlling error, where blocking is not so effective. Covariance analysis is most commonly used for this purpose. By measuring one or more covariates- the characters whose functional relationships to the character of primary interest are known, the analysis of covariance (ANCOVA) can reduce the variability among experimental units by adjusting their values to a common value of the covariates. For example, in an animal feeding trial, the initial weight of the animals usually differs. Using this initial weight as the covariate, final weight after the animals are subjected to various feeds (i.e., treatments) can be adjusted to the values that would have been attained had all experimental animals started with the same body weight. Or, in a rice field experiment where rats damaged some of the test plots, covariance analysis with rat damage as the covariate can adjust plot yields to the levels that they should have been with no rat damage in any plot. References "],["uniformity-trials.html", "Lecture: 2 Uniformity trials 2.1 How uniformity trial is performed 2.2 Fertility Contour Map 2.3 Serial Correlation 2.4 Mean square between strips 2.5 Fairfield Smiths Variance Law 2.6 Maximum Curvature Method 2.7 Uniformity trial explained", " Lecture: 2 Uniformity trials Uniformity trials, size and shape of plots and blocks Research worker would perform experiments in identical conditions to obtain valid results but even with the most uniform land that he can select, there will be still inherent variations in the soil. So, in order to maintain homogeneity, experimenter should have a good idea of the nature and extent of fertility variation in land. This can be obtained from the results of what are known as uniformity trials. Uniformity trials can also be planned to determine suitable size and shape of the plot and the number of plots in a block. Uniformity trials enable us to have an idea about the fertility variation of the field. 2.1 How uniformity trial is performed Uniformity trial was conducted to know the nature of the soil fertility gradient. Under uniformity trial, a particular variety of a crop will be sown on the entire experiment field and uniformly managed throughout the growing season without applying fertilizer. At the time of harvest a substantial border will be removed from all sides of the field. The remainder of the field will be divided into small plots which are termed as basic units. The size of the basic unit is decided by judgment, depending on the crop. Smaller the basic unit more accurate study on heterogeneity is possible. The produce from the basic unit will be harvested and recorded separately for each basic unit. The yield differences between the basic units are taken as the measure of soil heterogeneity of the study area. Several types of analysis are available to evaluate pattern of soil heterogeneity based on uniformity trial data. We will discuss some of the procedures in detail. 2.2 Fertility Contour Map An approach to describe the heterogeneity of land is to construct the fertility contour map. It is simple but informative presentation of soil heterogeneity. This is constructed by taking the moving averages of yields of unit plots and demarcating the regions of same fertility by considering those areas, which have yield of same magnitude. Taking moving average reduce the large random variation expected on small plots. 2.3 Serial Correlation Serial correlation procedure is generally used to test the randomness of a data set. However, it is also useful in the characterization of the trend in soil fertility using uniformity trial data. Horizontal and vertical serial correlations were calculated. These correlations give idea on whether fertility gradient was more pronounced horizontally or vertically. A low serial correlation indicates that fertile areas occur in spots and a high value indicates there is a gradient. \\[r_{s} = \\frac{\\sum_{i = 1}^{n}{X_{i}X_{i + 1} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}}{\\sum_{i = 1}^{n}{X_{i}}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}\\] where \\(X_{i}\\) is the value of ith basic unit and \\(n\\) is the number of basic units. 2.4 Mean square between strips This method is simpler to compute and it has the objective same as the serial correlation. Units are first combined as horizontal and vertical strips. Variability between strips were measured in each direction by mean square between strips. The relative size of two mean squares indicates whether fertility gradient was more pronounced horizontally or vertically. \\[\\text{Sum of square}\\left( \\text{Vertical} \\right)\\frac{\\sum_{i = 1}^{c}V_{i}^{2}}{r} - \\frac{G^{2}}{n}\\ \\] \\[\\text{Sum of square}\\left( \\text{Horizontal} \\right)\\frac{\\sum_{i = 1}^{c}H_{i}^{2}}{c} - \\frac{G^{2}}{n}\\ \\] \\[\\text{mean square}\\left( \\text{Vertical} \\right) = \\frac{\\text{Sum of square}\\left( \\text{vertical} \\right)}{c - 1}\\] \\[\\text{mean square}\\left( \\text{Horizontal} \\right) = \\frac{\\text{Sum of square}\\left( \\text{Horizontal} \\right)}{r - 1}\\] where \\(V_{i},H_{i}\\) are sum total of basic units in vertical and horizontal strips respectively; \\(r\\) is the number of rows and \\(c\\) is the number of columns. \\(n\\) is the total number of basic units; \\(n = r \\times c\\). \\(G\\) is the total of all the basic units. 2.5 Fairfield Smiths Variance Law Smith (1938) gave a empirical relations between variance and plot size. He developed an empirical model representing the relationship between plot size and variance of mean per plot. This model is given by the equation \\[V_{x} = \\frac{V_{1}}{x^{b}}\\] \\[\\log V_{x} = \\ \\log V_{1} - b\\log x\\] where \\(x\\) is number of basic units in a plot, \\(V_{x}\\) is the variance of mean per plot of \\(x\\) units, \\(V_{1}\\) is the variance of mean per plot of one unit, and \\(b\\) is the regression coefficient. The values of \\(b\\) is determined by the principle of least squares. \\(b\\) is called Smiths index of soil heterogeneity. The index gives a single value as quantitative measure of heterogeneity in the area. 2.5.1 Smiths index of soil heterogeneity Step-1 Combine the basic units to simulate plots of different sizes and shapes. Use only combinations that fit exactly into the whole area,i.e. the product of simulated plots and the number of basic units per plot must equal to the total number of basic units. Step-2 For each of the simulated plots constructed in Step-1, compute the yield total T as the sum of basic units to construct that plot and compute between plot variance \\(V_{(x)}\\) \\[V_{(x)} = \\sum_{i = 1}^{w}\\frac{{T_{i}}^{2}}{x} - \\frac{\\left( G \\right)^{2}}{\\text{rc}}\\] where \\(w = \\frac{\\text{rc}}{x}\\ \\)is the total number of simulated plots of size\\(\\text{\\ x}\\) basic units. \\(r\\) is the number of rows and \\(c\\) is the number of columns. \\(G\\) is the total of all the basic units. Step-3 For each plot size and shape, compute the variance per unit area \\[V_{x} = \\frac{V_{(x)}}{rc - 1}\\] Step-4 For each plot size having more than one shape, test the homogeneity of between-plot variances \\(\\mathbf{V}_{\\left( \\mathbf{x} \\right)}\\)to determine the significance of plot orientation (plot-shape) effect, by using the F test or the chi-square test. If found homogeneous, the average of \\(\\mathbf{V}_{\\mathbf{(x)}}\\) values over all plot shapes of a given size is computed, otherwise \\(\\mathbf{V}_{\\mathbf{(x)}}\\)of each plot shapes of a given size is used separately for further calculation. For example, there are two plot shapes for size 2m2 i.e. 2 × 1m and 1 × 2m. For both these plot \\(\\mathbf{V}_{\\mathbf{(x)}}\\)is calculated. Homogeneity is tested using F test. If it is non-significant the average of \\(\\mathbf{V}_{\\mathbf{(x)}}\\) values over the plot shapes 2 × 1m and 1 × 2m will be calculated. Step-5 Using the values of the variance per unit area \\(\\mathbf{V}_{\\mathbf{x}}\\) computed in steps 3 and 4, estimate the regression coefficient between \\(\\mathbf{V}_{\\mathbf{x}}\\) and plot size \\(\\mathbf{x}\\) Using Fairfield Smiths Variance Law, which can be written by taking logarithm to the base e as: \\[\\log V_{x} - \\log V_{1} = \\ - b\\log x\\] consider \\[{Y = \\log}V_{x} - \\log V_{1}\\] then equation \\(\\log V_{x} - \\log V_{1} = \\ - b\\log x\\) can be written in the form \\(\\mathbf{Y = \\ cX}\\) where \\(\\mathbf{c = \\ - b;\\ X =}\\mathbf{\\log}\\mathbf{x}\\) \\(\\mathbf{b}\\) is estimated by fitting regression between \\(\\mathbf{Y}\\) and \\(\\mathbf{X}\\). Step-6 Obtain the adjusted \\(\\mathbf{b}\\) from the computed \\(\\mathbf{b}\\) value using the range \\(\\frac{\\mathbf{x}_{\\mathbf{1}}}{\\mathbf{n}}\\), where\\(\\mathbf{\\ }\\mathbf{x}_{\\mathbf{1}}\\), is the size of basic unit and \\(\\mathbf{n}\\) is the whole area size. Column 2 and 3 in the table 2.1 is the range of \\(\\frac{\\mathbf{x}_{\\mathbf{1}}}{\\mathbf{n}}\\). once you get the computed \\(b\\) and value of \\(\\frac{\\mathbf{x}_{\\mathbf{1}}}{\\mathbf{n}}\\). You can calculate the corresponding adjusted \\(b\\) using the table 2.1. using interpolation as follows. Find L1 and L2 such that, calculated b lies between them; L1  bcal  L2, where L1 and L2 are the values in computed b column in table 2.1. Let y1 , y2 be the value corresponding to L1 and L2 under the range of \\(\\frac{\\mathbf{x}_{\\mathbf{1}}}{\\mathbf{n}}\\) in the table 2.1. Then using the formula Adjusted b value = \\(y_{1} + (b_{\\text{cal}} - L_{1})\\frac{\\left( y_{2} - y_{1} \\right)}{\\left( L_{2} - L_{1} \\right)}\\) Table 2.1: Adjusted b table. Obtain the value of b using the range values and computed b value Computed b Range 0.001 to 0.01 Range 0.01 to 0.1 1 1 1 0.8 0.804 0.822 0.7 0.71 0.738 0.6 0.617 0.656 0.5 0.528 0.578 0.4 0.443 0.504 0.35 0.403 0.469 0.3 0.364 0.434 0.25 0.326 0.402 0.2 0.291 0.371 0.1 0.257 0.343 0.15 0.226 0.312 A relatively low value of calculated adjusted Smith's index of soil heterogeneity (\\(\\mathbf{b}\\)) indicates a relatively high degree of correlation among adjacent plots in the study area, which indicates the change in the level of soil fertility tends to be gradual rather than in patches. Even though \\(\\mathbf{b}\\) is a regression coefficient its value lies between 0 and 1. 2.6 Maximum Curvature Method This method is used to find optimal plot size for the experiment. In this method basic units of uniformity trials are combined to form new units. The new units are formed by combining columns, rows or both. Combination of columns and rows be done in such a way that no columns or rows is left out. For each set of units, the coefficient of variation (CV) is computed. A curve is plotted by taking the plot size (in terms of basic units) on X-axis and the CV values on the Y-axis of graph sheet. The point at which the curve takes a turn, i.e., the point of maximum curvature is located by inspection. The value corresponding to the point of maximum curvature will be optimum plot size. 2.7 Uniformity trial explained Let us discuss in detail the procedures explained above using an example. Consider a rice crop field of 12m × 17m uniformly managed throughout the growing season without applying fertilizer. At the time of harvest a border of 1m is removed from all sides of the field. The resultant effective area is now 10m × 15m, entire field is divided in basic units of size 1m × 1m, and yield (in gms) were noted from each basic unit. There are 150 basic units. Figure 2.1: Yield observed from the plots of 1x1m size Note: here r=15;c=10 and total number of basic units n=r×c=150 2.7.1 Fertility contour map Also known as soil productivity contour map. construction fertility contour map is explained using above example. Step 1: Calculate moving averages of 3m×3m basic units. i.e including three basic units in rows and 3 basic units in columns. Figure 2.2: Calculation of moving averages of 3m×3m basic units Step 2: Moving averages where labeled as shown below. After calculation of moving averages now there are 8 values in a row and 13 values in a column. Now the dimension of each plot in the figure below can be considered as 1.25m × 1.154m (10/8 = 1.25 and 15/13 = 1.514) Figure 2.3: Moving averages recorded for all 3m×3m basic units Step 3: Similar areas where given same colours to get a fertility contour map. Figure 2.4: Colouring scheme based on range of moving averages. This can be decided by the experimenter Figure 2.5: Coloured plot labelled with moving averages Final fertility contour map is obtained as shown in figure 2.7. Now you can get an idea of fertility gradient of the field and plan how to create blocks in the field. Figure 2.6: Final fertility contour map Fertility contour map gives only a vague idea of fertilizer gradient. Other procedures may give a better idea. 2.7.2 Serial Correlation Pair wise calculation of vertical values from the experiment observations shown in figure 2.1 Figure 2.7: Pair wise calculation of vertical values Using \\(r_{s} = \\frac{\\sum_{i = 1}^{n}{X_{i}X_{i + 1} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}}{\\sum_{i = 1}^{n}{X_{i}}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}\\) Vertical \\(r_{s} = \\frac{100859156 - \\frac{\\left( 122777 \\right)^{2}}{150}}{101325715 - \\frac{\\left( 122777 \\right)^{2}}{150}}\\ \\)= 0.438627 Pair wise calculation of Horizontal values shown in figure 2.1 Figure 2.8: Pair wise calculation of horizontal values Using \\[r_{s} = \\frac{\\sum_{i = 1}^{n}{X_{i}X_{i + 1} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}}{\\sum_{i = 1}^{n}{X_{i}}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}X_{i} \\right)^{2}}{n}}\\] Horizontal \\(r_{s} = \\frac{100946042 - \\frac{\\left( 122777 \\right)^{2}}{150}}{101325715 - \\frac{\\left( 122777 \\right)^{2}}{150}}\\ \\)= 0.54317 Both coefficients are low which indicates the presence of fertile areas in spots. However, the horizontal serial correlation coefficient was little high than vertical implying that some fertility gradient in horizontal direction than vertical. The relative magnitude of the two serial correlations should not, however, be used to indicate the relative degree of the gradients in the two directions. 2.7.3 Mean square between strips Figure 2.9: Mean square between strips from uniformity trial data \\(G =\\) 122777, \\(n =\\) 150 \\(\\text{Sum}\\ \\text{of}\\ \\text{square}\\left( \\text{vertical} \\right)\\frac{\\sum_{i = 1}^{c}V_{i}^{2}}{r} - \\frac{G^{2}}{n} = \\frac{12686^{2} + 12816^{2} + \\ldots 12253^{2}}{15} - \\frac{122777^{2}}{150}\\) = 63971.47 \\(\\text{Sum}\\ \\text{of}\\ \\text{square}\\left( \\text{Horizontal} \\right)\\frac{\\sum_{i = 1}^{c}H_{i}^{2}}{c} - \\frac{G^{2}}{n} = \\frac{8874^{2} + 8877^{2} + \\ldots 7692^{2}}{10} - \\frac{7725^{2}}{150}\\ \\)= 341185.7733 \\(\\text{mean}\\ \\text{square}\\left( \\text{vertical} \\right) = \\frac{63971.47}{9}\\ \\)= 7107.941481 \\(\\text{mean}\\ \\text{square}\\left( \\text{Horizontal} \\right) = \\frac{341185.773}{14}\\ \\)= 24370.41238 Results show that the horizontal-strip MS is almost 3 times higher than the vertical-strip MS, indicating that the trend of soil fertility was more pronounced along the length than along width of the field. 2.7.4 Smiths index of soil heterogeneity Optimal plot size can be identified using this method. From the possible plot sizes optimum plot size can be found out using method explained in section 2.5.1. Table below shows 9 different plot sizes created from uniformity trial data in figure 2.1. Sl. No. Size of plot (x) Width Length No: of plots (\\(w\\)) 1 1 1 1 150 2 2 2 1 75 3 3 1 3 50 4 5 1 5 30 5 5 5 1 30 6 6 2 3 25 7 10 2 5 15 8 15 5 3 10 9 25 5 5 6 It is recommended that the reader should first read section 2.5.1 and then read this example. Here, I will illustrate how variance per unit area for a plot of size 25m2 (denoted as V25) is calculated. The width and length of the plot is 5m × 5m. The entire plot area in figure 2.1 is divided in to six plots of size 25m2 as shown below. Figure 2.10: Uniformity trail plot in figure 2.1 is divided in to six plots Now consider the equation for between plot variance \\(V_{(x)} = \\sum_{i = 1}^{w}\\frac{{T_{i}}^{2}}{x} - \\frac{\\left( G \\right)^{2}}{\\text{rc}}\\). where \\(w = \\frac{\\text{rc}}{x}\\ \\)is the total number of simulated plots of size\\(\\text{\\ x}\\) basic units. \\(r\\) is the number of rows and \\(c\\) is the number of columns. \\(G\\) is the total of all the basic units. Figure 2.11: Totals of each of six plots \\(V_{(25)} = \\frac{21366^{2} + 21433^{2}\\ldots + 18811^{2}}{25} - \\frac{\\left( 122777 \\right)^{2}}{150} = \\ \\)218767.7133 Variance per unit area is given by \\(V_{x} = \\frac{V_{(x)}}{rc - 1}\\) \\(V_{25} = \\frac{218767.7133}{149}\\ = \\ \\)1468.24 Coefficient of variation is calculated as \\(\\frac{\\text{Standard\\ deviation}}{\\text{mean}} \\times 100\\), here in this example of plot size 25. Standard deviation= \\(\\sqrt{1468.24}\\) = 38.31762. Mean of entire data set = 818.5133. Therefore C.V = \\(\\frac{38.31762}{818.5133} = 0.047\\). Similarly, it can be calculated for all the plot sizes. Vx and C.V for all other plot sizes are summarized below. Sl. No. Size of plot (x) Width Length No: of plots (\\(w\\)) Vx C.V 1 1 1 1 150 5577.88 9.1 2 2 2 1 75 4427.18 8.1 3 3 1 3 50 3733.36 7.5 4 5 1 5 30 2213.82 5.7 5 5 5 1 30 3066.42 6.8 6 6 2 3 25 3316.61 7 7 10 2 5 15 2003.03 5.5 8 15 5 3 10 2268.41 5.8 9 25 5 5 6 1468.24 4.7 For each plot size having more than one shape (here plot size 5 have more than one shape), test the homogeneity of between-plot variances V(x), to determine the significance of plot orientation (plot-shape) effect, by using the F test or the chi-square test. For each plot size whose plot-shape effect is non-significant, compute the average of Vx, values over all plot shapes and proceed with estimation of Smith's index of soil heterogeneity. V(x) calculated for both plot sizes Plot shapes V(x) 1×5 456895.9 5×1 329859.5 Degrees of freedom for F test are \\((w_{1} - 1,\\ w_{2} - 1)\\), where \\(w_{1}\\) and \\(w_{2}\\) are number of plots of particular shapes each. Here, degrees of freedom = (30-1, 30-1)=(29,29). F is calculated as the ratio of V(x) of both plot shapes. Fcal= \\(\\frac{456895.9}{329859.5}\\) =1.38. Calculated value of F (Fcal) is compared with table value of F. Table value of F at (29,29) degrees of freedom, Ftable= 1.860. Since Fcal &lt; Ftable; Calculated F is non-significant, so take average of Vx of both plot shapes and proceed. In our example we proceeded without taking the average. I included this example of F test for a better understanding of the theory written. Now Smith's index of soil heterogeneity is estimated as follows Size of plot (x) Vx log(Vx) Y = log(Vx) -log(V1) X = log(x) 1 5577.88 8.62656 0 0 2 4427.18 8.39552 -0.231045 0.6931472 3 3733.36 8.22506 -0.401499 1.0986123 5 2213.82 7.70248 -0.924087 1.6094379 5 3066.42 8.02826 -0.598299 1.6094379 6 3316.61 8.1067 -0.519865 1.7917595 10 2003.03 7.60242 -1.024146 2.3025851 15 2268.41 7.72683 -0.899731 2.7080502 25 1468.24 7.29182 -1.334744 3.2188758 V1 = 5577.88; log(V1) = 8.62656 Fit a linear regression Y = cX, estimate the value of c; c= -b Estimated value of c is -0.3952. Therefore, calculated value of b = 0.3952. In our case \\(\\text{}\\frac{x_{1}}{n} = \\frac{1}{150} = 0.0067\\). Now we need to find the adjusted value as explained in step-6 in section 2.5.1 using the table below.The value of \\(\\frac{x_{1}}{n} = \\frac{1}{150} = 0.0067\\) is between 0.001 and 0.01. Here \\(b_{\\text{cal}}\\)= 0.3952 \\(y_{1}\\) = 0.443 \\(y_{2}\\) = 0.528 \\(L_{1}\\)= 0.40 \\(L_{2}\\) = 0.50 Adjusted b value = \\(0.443 + (0.3952 - 0.40)\\frac{\\left( 0.528 - 0.443 \\right)}{\\left( 0.50 - 0.40 \\right)}\\) = 0.43892. Computed b 0.001 to 0.01 0.01 to 0.1 1.00 1.000 1.000 0.80 0.804 0.822 0.70 0.710 0.738 0.60 0.617 0.656 0.50 0.528 0.578 0.40 0.443 0.504 0.35 0.403 0.469 0.30 0.364 0.434 0.25 0.326 0.402 0.20 0.291 0.371 0.10 0.257 0.343 0.15 0.226 0.312 If \\(b\\) value is low it indicates a relatively high degree of correlation among adjacent plots in the study area indicating a gradual change in soil fertility. But here \\(b\\) is 0.43892, which is moderate, so there is no indication of gradient but slight indication of patches. 2.7.5 Maximum Curvature Method This method (see section 2.6) is used to find optimum plot size. A curve is plotted by taking the plot size (in terms of basic units) on X-axis and the CV values on the Y-axis. Figure 2.12: Relationship between CV and plot size Figure 2.12indicates that as the plot size increases, coefficients of variation decreases and this decrease is maximum with the square shape plot of 5m×5m. As we took a small data set for illustrative purpose, it is clearly seen that 5m×5m plot has the lowest CV value and also lowest variance per basic unit area. Figure 2.13: Relationship between variance per basic unit area and plot size Figure 2.13 shows the relationship between variance per basic unit area Vx and plot size (x) "],["analysis-of-variance-anova.html", "Lecture: 3 Analysis of Variance (ANOVA) 3.1 Null hypothesis in ANOVA 3.2 Degrees of freedom 3.3 Test Statistic F 3.4 Assumptions of ANOVA 3.5 Models under ANOVA 3.6 One-way ANOVA 3.7 Two-way ANOVA", " Lecture: 3 Analysis of Variance (ANOVA) Consider an example where three chemical fertilizers A, B, C are tested on potted plants. Experimenter would like to identify, which among the fertilizer among A, B and C gives the highest yield. Potted plants are maintained in the same way; so that experimental conditions are homogenous. Now after collecting yield data from the plants, you can observe a variance i.e., the yield values are not same. Here, this variation is caused by the treatment and experimental error. So, the total observed variance = variance due to treatments + variance due to error. So, in this example treatment and error can be considered as the source of variation in the data. Basically, any experiment you perform is a sample based on which you make generalization about the population. Now, based on your experiment you want to test whether the means of treatment A, B and C are significantly different considering that the observed difference is not by chance taking in to account experimental error variance. Analysis of variance (ANOVA) is a statistical procedure used to analyze the differences among means, where the observed total variance is partitioned into components attributable to different sources of variation. The logic behind is simple, if much of the variation comes from the treatment, it is more likely that the mean of treatments is different. This variation is compared with the experimental error variance, larger the ratio of treatment variance to error variance, the more likely that the groups have different means. The term \"analysis of variance\" originates from how the analysis uses variances to determine whether the means are different. ANOVA works by comparing the variance of treatments (between group variance) to the error variance (within group variance). In short ANOVA is a statistical hypothesis test that determines whether the means of at least two populations are different. ANOVA was developed by the statistician Sir Ronald A. Fisher. 3.1 Null hypothesis in ANOVA Null hypothesis in ANOVA is that population means are equal, which is denoted as H0: µ1 = µ2 =µ3 = ., = µk . Alternate hypothesis, H1: µ1  µ2  µ3 .., µk. Where µ1, µ2, µ3, , µk are k population means 3.2 Degrees of freedom Before proceeding, it is important to understand the concept of degrees of freedom. Degrees of freedom can be defined as the number of independent observations that are free to vary. Consider a simple example, you have 7 hats and you want to wear a different hat every day of the week. On the first day, you can wear any of the 7 hats. On the second day, you can choose from the 6 remaining hats, on day 3 you can choose from 5 hats, and so on. When day 6 rolls around, you still have a choice between 2 hats that you havent worn yet that week. But after you choose your hat for day 6, you have no choice for the hat that you wear on Day 7. You must wear the one remaining hat. You had 7-1 = 6 days of hat freedomin which the hat you wore could vary! Degrees of freedom can also be defined as the number of independent values, which were included into calculation of an estimate. An estimate is a single number that expresses some property of a population from a sample. It can be mean, median, standard deviation, or variance that is calculated from a sample. And there are independent values (or observations) that went into formula calculation. The quantity of these values is called degrees of freedom. Consider three observations 6, x and 9. Here x is unknown and suppose we know the mean is 6. Then we can say x is exactly equal to 3, because mean is 6. Here two values are free to vary but the third value depends on other two under the constraint that their mean should be 6. i.e. if other two values are changed third value will also change. Now consider the height of 7 students 164, 173, 158, 179, 168, 187, 167. Mean: 170.85 We can find standard deviation using two formulas SD= \\(\\frac{\\sum_{}^{}\\left( x_{i} - \\overline{x} \\right)^{2}}{n}\\), where n is the number of observations Here SD = 9 SD= \\(\\frac{\\sum_{}^{}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1}\\), where n-1 is the degrees of freedom Here SD = 9.72 It is easy to notice that when we divide by degrees of freedom, we make our estimate of standard deviation greater than if we were diving only by sample size. But why do we need to make it greater? As weve already calculated the mean, we dont have to use all the data in order to estimate the standard deviation. It does not depend on each piece of information, and the last observation does not contribute to the standard deviation. So, if we dont delete this redundant data, then we underestimate the standard deviation of population from sample data. So here using the degrees of freedom in the denominator provides an unbiased estimate of population standard deviation. Degrees of freedom also define the probability distributions for the test statistics of various hypothesis tests. For example, hypothesis tests use the t-distribution, F-distribution, and the chi-square distribution to determine statistical significance. Each of these probability distributions is a family of distributions where the DF define the shape. Hypothesis tests use these distributions to make decisions on null hypothesis. ## Mean squares 3.3 Test Statistic F Any function of sample values is known as a statistic. For example, sample mean, sample variance, sum of all sample values are statistic, because these are all some functions of sample values. If a statistic is used to test a hypothesis, then it is known as test statistic. Examples of test statistic are t, F, 2 etc. The test statistic used in ANOVA is F. F-statistic is the ratio of two variances and it was named after Sir Ronald A. Fisher. It is proved that when null hypothesis H0: µ1 = µ2 =µ3 = ., = µk is true the ratio of mean square treatment and mean square error follows F distribution. In general, if your calculated F value in ANOVA is larger than your F critical value, you can reject the null hypothesis. Figure 3.1: Distribution F under different degrees of freedom 3.4 Assumptions of ANOVA 3.5 Models under ANOVA 3.6 One-way ANOVA 3.7 Two-way ANOVA "],["references.html", "Lecture: 4 References", " Lecture: 4 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
